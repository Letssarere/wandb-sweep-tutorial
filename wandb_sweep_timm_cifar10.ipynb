{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "from torchvision import datasets, transforms\n",
    "from typing import Dict, Any, Tuple, Optional\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AsymmetricLoss(nn.Module):\n",
    "    \"\"\"Asymmetric Loss for multi-label classification\"\"\"\n",
    "    def __init__(self, gamma_neg=4, gamma_pos=1, clip=0.05, eps=1e-8, disable_torch_grad_focal_loss=False):\n",
    "        super(AsymmetricLoss, self).__init__()\n",
    "        self.gamma_neg = gamma_neg\n",
    "        self.gamma_pos = gamma_pos\n",
    "        self.clip = clip\n",
    "        self.disable_torch_grad_focal_loss = disable_torch_grad_focal_loss\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        \"\"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: input logits\n",
    "        y: targets (multi-label binarized vector)\n",
    "        \"\"\"\n",
    "        # Calculating Probabilities\n",
    "        x_sigmoid = torch.sigmoid(x)\n",
    "        xs_pos = x_sigmoid\n",
    "        xs_neg = 1 - x_sigmoid\n",
    "\n",
    "        # Asymmetric Clipping\n",
    "        if self.clip is not None and self.clip > 0:\n",
    "            xs_neg = (xs_neg + self.clip).clamp(max=1)\n",
    "\n",
    "        # Basic CE calculation\n",
    "        los_pos = y * torch.log(xs_pos.clamp(min=self.eps))\n",
    "        los_neg = (1 - y) * torch.log(xs_neg.clamp(min=self.eps))\n",
    "\n",
    "        # Asymmetric Focusing\n",
    "        if self.gamma_neg > 0 or self.gamma_pos > 0:\n",
    "            if self.disable_torch_grad_focal_loss:\n",
    "                torch.set_grad_enabled(False)\n",
    "            pt0 = xs_pos * y\n",
    "            pt1 = xs_neg * (1 - y)\n",
    "            pt = pt0 + pt1\n",
    "            one_sided_gamma = self.gamma_pos * y + self.gamma_neg * (1 - y)\n",
    "            one_sided_w = torch.pow(1 - pt, one_sided_gamma)\n",
    "            if self.disable_torch_grad_focal_loss:\n",
    "                torch.set_grad_enabled(True)\n",
    "            los_pos *= one_sided_w\n",
    "            los_neg *= one_sided_w\n",
    "\n",
    "        return -(los_pos + los_neg).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"Focal Loss for dealing with class imbalance\"\"\"\n",
    "    def __init__(self, alpha=1, gamma=2):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * (1-pt)**self.gamma * ce_loss\n",
    "        return focal_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelManager:\n",
    "    \"\"\"TIMM 모델 및 학습 관리\"\"\"\n",
    "    def __init__(self):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.checkpoint_dir = Path(\"model_checkpoints\")\n",
    "        \n",
    "        if not self.checkpoint_dir.is_dir():\n",
    "            self.checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        self.classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "                       'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_sweep_config() -> Dict[str, Any]:\n",
    "        \"\"\"WandB sweep 설정 반환\"\"\"\n",
    "        return {\n",
    "            'method': 'random',\n",
    "            'metric': {\n",
    "                'name': 'val_loss',\n",
    "                'goal': 'minimize'\n",
    "            },\n",
    "            'parameters': {\n",
    "                'model_name': {\n",
    "                    # CIFAR-10에 적합한 작은/중간 크기 모델들 선택\n",
    "                    'values': [\n",
    "                        'resnet18',\n",
    "                        'mobilenetv3_small_100',\n",
    "                        'efficientnet_b0',\n",
    "                        'vit_tiny_patch16_224',\n",
    "                        'convnext_tiny',\n",
    "                        'mobilevitv2_050'\n",
    "                    ]\n",
    "                },\n",
    "                'optimizer': {\n",
    "                    'values': ['adam', 'sgd', 'adamw']\n",
    "                },\n",
    "                'loss_function': {\n",
    "                    'values': ['cross_entropy', 'focal']\n",
    "                },\n",
    "                'dropout': {\n",
    "                    'values': [0.3, 0.4, 0.5]\n",
    "                },\n",
    "                'learning_rate': {\n",
    "                    'distribution': 'log_uniform',\n",
    "                    'min': -9.21,  # log(1e-4)\n",
    "                    'max': -4.61   # log(1e-2)\n",
    "                },\n",
    "                'batch_size': {\n",
    "                    'distribution': 'q_log_uniform_values',\n",
    "                    'q': 8,\n",
    "                    'min': 32,\n",
    "                    'max': 256,\n",
    "                },\n",
    "                'epochs': {\n",
    "                    'value': 5\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def get_model(self, model_name: str, num_classes: int) -> nn.Module:\n",
    "        \"\"\"TIMM 모델 로드 및 CIFAR-10 크기에 맞게 조정\"\"\"\n",
    "        if 'vit_tiny_patch16_224' in model_name:\n",
    "            # ViT 모델의 경우에만 patch_size 적용\n",
    "            model = timm.create_model(\n",
    "                model_name,\n",
    "                pretrained=True,\n",
    "                num_classes=num_classes,\n",
    "                img_size=32,\n",
    "                patch_size=4  # 32x32 이미지에 맞게 patch size 조정\n",
    "            )\n",
    "        else:\n",
    "            # 다른 모델들의 경우\n",
    "            model = timm.create_model(\n",
    "                model_name,\n",
    "                pretrained=True,\n",
    "                num_classes=num_classes,\n",
    "                in_chans=3\n",
    "            )\n",
    "                \n",
    "        return model.to(self.device)\n",
    "    \n",
    "    def get_loss_function(self, loss_name: str) -> nn.Module:\n",
    "        \"\"\"Loss function 생성\"\"\"\n",
    "        if loss_name == 'focal':\n",
    "            return FocalLoss()\n",
    "        # elif loss_name == 'asymmetric':\n",
    "        #     return AsymmetricLoss()\n",
    "        return nn.CrossEntropyLoss()\n",
    "\n",
    "    def get_optimizer(self, model: nn.Module, optimizer_name: str, learning_rate: float) -> torch.optim.Optimizer:\n",
    "        \"\"\"옵티마이저 생성\"\"\"\n",
    "        if optimizer_name == \"sgd\":\n",
    "            return optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "        elif optimizer_name == \"adamw\":\n",
    "            return optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "        return optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    def get_data_loaders(self, batch_size: int) -> Tuple[torch.utils.data.DataLoader, torch.utils.data.DataLoader]:\n",
    "        \"\"\"CIFAR-10 데이터 로더 생성\"\"\"\n",
    "        # CIFAR-10에 최적화된 데이터 증강\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.4914, 0.4822, 0.4465],\n",
    "                std=[0.2470, 0.2435, 0.2616]\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        test_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.4914, 0.4822, 0.4465],\n",
    "                std=[0.2470, 0.2435, 0.2616]\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        train_dataset = datasets.CIFAR10(\n",
    "            root='./data',\n",
    "            train=True,\n",
    "            download=True,\n",
    "            transform=train_transform\n",
    "        )\n",
    "        \n",
    "        val_dataset = datasets.CIFAR10(\n",
    "            root='./data',\n",
    "            train=False,\n",
    "            download=True,\n",
    "            transform=test_transform\n",
    "        )\n",
    "        \n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=2,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        val_loader = torch.utils.data.DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=2,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        return train_loader, val_loader\n",
    "    \n",
    "    def save_best_model(self, model: nn.Module, config: wandb.Config, val_loss: float):\n",
    "        \"\"\"최고 성능 모델 저장\"\"\"\n",
    "        checkpoint_name = f\"{config.model_name}_{config.optimizer}_{config.loss_function}_loss{val_loss:.4f}.pth\"\n",
    "        checkpoint_path = self.checkpoint_dir / checkpoint_name\n",
    "\n",
    "        # 같은 조합의 이전 체크포인트 삭제\n",
    "        for old_checkpoint in self.checkpoint_dir.glob(f\"{config.model_name}_{config.optimizer}_{config.loss_function}_*.pth\"):\n",
    "            os.remove(old_checkpoint)\n",
    "\n",
    "        # 항상 저장\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'config': dict(config),\n",
    "            'val_loss': val_loss\n",
    "        }, checkpoint_path)\n",
    "\n",
    "    \n",
    "    def train_epoch(self, model: nn.Module, loader: torch.utils.data.DataLoader,\n",
    "                   criterion: nn.Module, optimizer: torch.optim.Optimizer) -> Tuple[float, float]:\n",
    "        \"\"\"한 에폭 학습 수행\"\"\"\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for data, target in loader:\n",
    "            data, target = data.to(self.device), target.to(self.device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # 정확도 계산\n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            wandb.log({\n",
    "                \"batch_loss\": loss.item(),\n",
    "                \"batch_accuracy\": 100. * correct / total\n",
    "            })\n",
    "            \n",
    "        epoch_loss = total_loss / len(loader)\n",
    "        epoch_acc = 100. * correct / total\n",
    "        return epoch_loss, epoch_acc\n",
    "    \n",
    "    def validate(self, model: nn.Module, loader: torch.utils.data.DataLoader,\n",
    "                criterion: nn.Module) -> Tuple[float, float]:\n",
    "        \"\"\"검증 수행\"\"\"\n",
    "        model.eval()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, target in loader:\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                total_loss += loss.item()\n",
    "                \n",
    "                # 정확도 계산\n",
    "                _, predicted = output.max(1)\n",
    "                total += target.size(0)\n",
    "                correct += predicted.eq(target).sum().item()\n",
    "        \n",
    "        val_loss = total_loss / len(loader)\n",
    "        val_acc = 100. * correct / total\n",
    "        return val_loss, val_acc\n",
    "    \n",
    "    def train(self, config: wandb.Config = None):\n",
    "        \"\"\"전체 학습 프로세스 실행\"\"\"\n",
    "        with wandb.init(config=config):\n",
    "            config = wandb.config\n",
    "            \n",
    "            # 모델, 데이터, 손실함수, 옵티마이저 초기화\n",
    "            model = self.get_model(config.model_name, num_classes=10)\n",
    "            train_loader, val_loader = self.get_data_loaders(config.batch_size)\n",
    "            criterion = self.get_loss_function(config.loss_function)\n",
    "            optimizer = self.get_optimizer(model, config.optimizer, config.learning_rate)\n",
    "            \n",
    "            best_val_loss = float('inf')\n",
    "            \n",
    "            # wandb에 클래스 이름 기록\n",
    "            wandb.config.update({\"classes\": self.classes})\n",
    "            \n",
    "            # 학습 수행\n",
    "            for epoch in range(config.epochs):\n",
    "                train_loss, train_acc = self.train_epoch(model, train_loader, criterion, optimizer)\n",
    "                val_loss, val_acc = self.validate(model, val_loader, criterion)\n",
    "                \n",
    "                wandb.log({\n",
    "                    \"train_loss\": train_loss,\n",
    "                    \"train_accuracy\": train_acc,\n",
    "                    \"val_loss\": val_loss,\n",
    "                    \"val_accuracy\": val_acc,\n",
    "                    \"epoch\": epoch\n",
    "                })\n",
    "                \n",
    "                # 최고 성능 모델 저장\n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    self.save_best_model(model, config, val_loss)\n",
    "                    # 모델 저장했다는 메시지 출력\n",
    "                    print(f\"Model saved with loss: {val_loss:.4f}\")\n",
    "                else:\n",
    "                    print(f\"Model not saved, best loss: {best_val_loss:.4f}\")\n",
    "                    \n",
    "                    \n",
    "                print(f'Epoch: {epoch+1}/{config.epochs}')\n",
    "                print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "                print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "                print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"메인 실행 함수\"\"\"\n",
    "    wandb.login(key=\"c59a3db1bd9de26ab7b58ea9df28add1357ec84b\")\n",
    "    \n",
    "    # 모델 매니저 초기화\n",
    "    manager = ModelManager()\n",
    "    \n",
    "    # Sweep 설정 및 실행\n",
    "    sweep_config = manager.get_sweep_config()\n",
    "    sweep_id = wandb.sweep(sweep_config, project=\"timm-cifar10-sweeps-5\")\n",
    "    \n",
    "    # Sweep Agent 실행\n",
    "    wandb.agent(sweep_id, function=manager.train, count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mxyztomas\u001b[0m (\u001b[33mxyztomas-xyz\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/jun/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Malformed sweep config detected! This may cause your sweep to behave in unexpected ways.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m To avoid this, please fix the sweep config schema violations below:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m   Violation 1. learning_rate uses log_uniform, where min/max specify base-e exponents. Use log_uniform_values to specify limit values.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 8428yi1m\n",
      "Sweep URL: https://wandb.ai/juno95/timm-cifar10-sweeps-5/sweeps/8428yi1m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: h73hggbd with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 144\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0036139350384962743\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_function: focal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_name: mobilevitv2_050\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjuno95\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jun/github/wandb_train_example/wandb/run-20241217_102744-h73hggbd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/juno95/timm-cifar10-sweeps-5/runs/h73hggbd' target=\"_blank\">feasible-sweep-1</a></strong> to <a href='https://wandb.ai/juno95/timm-cifar10-sweeps-5' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/juno95/timm-cifar10-sweeps-5/sweeps/8428yi1m' target=\"_blank\">https://wandb.ai/juno95/timm-cifar10-sweeps-5/sweeps/8428yi1m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/juno95/timm-cifar10-sweeps-5' target=\"_blank\">https://wandb.ai/juno95/timm-cifar10-sweeps-5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/juno95/timm-cifar10-sweeps-5/sweeps/8428yi1m' target=\"_blank\">https://wandb.ai/juno95/timm-cifar10-sweeps-5/sweeps/8428yi1m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/juno95/timm-cifar10-sweeps-5/runs/h73hggbd' target=\"_blank\">https://wandb.ai/juno95/timm-cifar10-sweeps-5/runs/h73hggbd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [04:43<00:00, 601kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n",
      "Model saved with loss: 0.3996\n",
      "Epoch: 1/5\n",
      "Train Loss: 0.5830, Train Acc: 65.95%\n",
      "Val Loss: 0.3996, Val Acc: 73.17%\n",
      "--------------------------------------------------\n",
      "Model saved with loss: 0.3306\n",
      "Epoch: 2/5\n",
      "Train Loss: 0.3486, Train Acc: 77.33%\n",
      "Val Loss: 0.3306, Val Acc: 78.60%\n",
      "--------------------------------------------------\n",
      "Model saved with loss: 0.3000\n",
      "Epoch: 3/5\n",
      "Train Loss: 0.2963, Train Acc: 80.16%\n",
      "Val Loss: 0.3000, Val Acc: 80.57%\n",
      "--------------------------------------------------\n",
      "Model saved with loss: 0.2871\n",
      "Epoch: 4/5\n",
      "Train Loss: 0.2710, Train Acc: 81.37%\n",
      "Val Loss: 0.2871, Val Acc: 81.30%\n",
      "--------------------------------------------------\n",
      "Model saved with loss: 0.2646\n",
      "Epoch: 5/5\n",
      "Train Loss: 0.2488, Train Acc: 82.69%\n",
      "Val Loss: 0.2646, Val Acc: 82.38%\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_accuracy</td><td>▁▂▂▃▄▅▅▆▆▆▇▇▇▇▇▇▇▇██████████████████████</td></tr><tr><td>batch_loss</td><td>▇▆█▆▅▅█▄▅▇▆▅▅▅▅▄▃▂▄▄▄▅▂▅▄▃▃▃▄▃▄▄▃▄▂▄▃▄▂▁</td></tr><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_accuracy</td><td>▁▆▇▇█</td></tr><tr><td>train_loss</td><td>█▃▂▁▁</td></tr><tr><td>val_accuracy</td><td>▁▅▇▇█</td></tr><tr><td>val_loss</td><td>█▄▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_accuracy</td><td>82.686</td></tr><tr><td>batch_loss</td><td>0.22207</td></tr><tr><td>epoch</td><td>4</td></tr><tr><td>train_accuracy</td><td>82.686</td></tr><tr><td>train_loss</td><td>0.24878</td></tr><tr><td>val_accuracy</td><td>82.38</td></tr><tr><td>val_loss</td><td>0.26457</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">feasible-sweep-1</strong> at: <a href='https://wandb.ai/juno95/timm-cifar10-sweeps-5/runs/h73hggbd' target=\"_blank\">https://wandb.ai/juno95/timm-cifar10-sweeps-5/runs/h73hggbd</a><br> View project at: <a href='https://wandb.ai/juno95/timm-cifar10-sweeps-5' target=\"_blank\">https://wandb.ai/juno95/timm-cifar10-sweeps-5</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241217_102744-h73hggbd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 82i29xp0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 136\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001895754175963262\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_function: focal\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_name: resnet18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jun/github/wandb_train_example/wandb/run-20241217_103333-82i29xp0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/juno95/timm-cifar10-sweeps-5/runs/82i29xp0' target=\"_blank\">silver-sweep-2</a></strong> to <a href='https://wandb.ai/juno95/timm-cifar10-sweeps-5' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/juno95/timm-cifar10-sweeps-5/sweeps/8428yi1m' target=\"_blank\">https://wandb.ai/juno95/timm-cifar10-sweeps-5/sweeps/8428yi1m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/juno95/timm-cifar10-sweeps-5' target=\"_blank\">https://wandb.ai/juno95/timm-cifar10-sweeps-5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/juno95/timm-cifar10-sweeps-5/sweeps/8428yi1m' target=\"_blank\">https://wandb.ai/juno95/timm-cifar10-sweeps-5/sweeps/8428yi1m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/juno95/timm-cifar10-sweeps-5/runs/82i29xp0' target=\"_blank\">https://wandb.ai/juno95/timm-cifar10-sweeps-5/runs/82i29xp0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Model saved with loss: 0.4712\n",
      "Epoch: 1/5\n",
      "Train Loss: 0.7308, Train Acc: 59.92%\n",
      "Val Loss: 0.4712, Val Acc: 71.53%\n",
      "--------------------------------------------------\n",
      "Model saved with loss: 0.3709\n",
      "Epoch: 2/5\n",
      "Train Loss: 0.4208, Train Acc: 73.89%\n",
      "Val Loss: 0.3709, Val Acc: 76.25%\n",
      "--------------------------------------------------\n",
      "Model saved with loss: 0.3218\n",
      "Epoch: 3/5\n",
      "Train Loss: 0.3488, Train Acc: 77.09%\n",
      "Val Loss: 0.3218, Val Acc: 79.02%\n",
      "--------------------------------------------------\n",
      "Model not saved, best loss: 0.3218\n",
      "Epoch: 4/5\n",
      "Train Loss: 0.3084, Train Acc: 79.50%\n",
      "Val Loss: 0.3440, Val Acc: 78.43%\n",
      "--------------------------------------------------\n",
      "Model saved with loss: 0.3073\n",
      "Epoch: 5/5\n",
      "Train Loss: 0.2818, Train Acc: 80.73%\n",
      "Val Loss: 0.3073, Val Acc: 79.90%\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_accuracy</td><td>▁▃▃▄▄▅▅▅▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████</td></tr><tr><td>batch_loss</td><td>▇█▅▅▅▄▄▃▂▃▂▃▃▃▃▃▃▂▂▂▂▂▂▂▃▂▂▃▃▂▂▁▂▂▂▃▃▁▁▂</td></tr><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_accuracy</td><td>▁▆▇██</td></tr><tr><td>train_loss</td><td>█▃▂▁▁</td></tr><tr><td>val_accuracy</td><td>▁▅▇▇█</td></tr><tr><td>val_loss</td><td>█▄▂▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_accuracy</td><td>80.732</td></tr><tr><td>batch_loss</td><td>0.29803</td></tr><tr><td>epoch</td><td>4</td></tr><tr><td>train_accuracy</td><td>80.732</td></tr><tr><td>train_loss</td><td>0.28183</td></tr><tr><td>val_accuracy</td><td>79.9</td></tr><tr><td>val_loss</td><td>0.30726</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">silver-sweep-2</strong> at: <a href='https://wandb.ai/juno95/timm-cifar10-sweeps-5/runs/82i29xp0' target=\"_blank\">https://wandb.ai/juno95/timm-cifar10-sweeps-5/runs/82i29xp0</a><br> View project at: <a href='https://wandb.ai/juno95/timm-cifar10-sweeps-5' target=\"_blank\">https://wandb.ai/juno95/timm-cifar10-sweeps-5</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241217_103333-82i29xp0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5600gpn4 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 248\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0036500270066907262\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_function: cross_entropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_name: vit_tiny_patch16_224\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a97ef39a942444e9b77f91e72b156ad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011114527700313678, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jun/github/wandb_train_example/wandb/run-20241217_103430-5600gpn4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/juno95/timm-cifar10-sweeps-5/runs/5600gpn4' target=\"_blank\">decent-sweep-3</a></strong> to <a href='https://wandb.ai/juno95/timm-cifar10-sweeps-5' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/juno95/timm-cifar10-sweeps-5/sweeps/8428yi1m' target=\"_blank\">https://wandb.ai/juno95/timm-cifar10-sweeps-5/sweeps/8428yi1m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/juno95/timm-cifar10-sweeps-5' target=\"_blank\">https://wandb.ai/juno95/timm-cifar10-sweeps-5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/juno95/timm-cifar10-sweeps-5/sweeps/8428yi1m' target=\"_blank\">https://wandb.ai/juno95/timm-cifar10-sweeps-5/sweeps/8428yi1m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/juno95/timm-cifar10-sweeps-5/runs/5600gpn4' target=\"_blank\">https://wandb.ai/juno95/timm-cifar10-sweeps-5/runs/5600gpn4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Model saved with loss: 1.7473\n",
      "Epoch: 1/5\n",
      "Train Loss: 2.0911, Train Acc: 22.25%\n",
      "Val Loss: 1.7473, Val Acc: 32.07%\n",
      "--------------------------------------------------\n",
      "Model saved with loss: 1.5896\n",
      "Epoch: 2/5\n",
      "Train Loss: 1.6957, Train Acc: 36.81%\n",
      "Val Loss: 1.5896, Val Acc: 41.82%\n",
      "--------------------------------------------------\n",
      "Model saved with loss: 1.5207\n",
      "Epoch: 3/5\n",
      "Train Loss: 1.5853, Train Acc: 41.54%\n",
      "Val Loss: 1.5207, Val Acc: 44.14%\n",
      "--------------------------------------------------\n",
      "Model saved with loss: 1.4995\n",
      "Epoch: 4/5\n",
      "Train Loss: 1.5365, Train Acc: 43.83%\n",
      "Val Loss: 1.4995, Val Acc: 44.39%\n",
      "--------------------------------------------------\n",
      "Model saved with loss: 1.4267\n",
      "Epoch: 5/5\n",
      "Train Loss: 1.5207, Train Acc: 44.23%\n",
      "Val Loss: 1.4267, Val Acc: 47.07%\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_accuracy</td><td>▁▁▁▂▂▃▃▅▆▆▆▆▇▇▇▇▇▇▇▇████████████████████</td></tr><tr><td>batch_loss</td><td>█▇▆▄▄▅▄▄▄▃▃▃▃▃▃▂▁▂▁▂▂▂▂▂▂▂▂▂▁▁▂▂▂▁▁▂▁▂▂▁</td></tr><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_accuracy</td><td>▁▆▇██</td></tr><tr><td>train_loss</td><td>█▃▂▁▁</td></tr><tr><td>val_accuracy</td><td>▁▆▇▇█</td></tr><tr><td>val_loss</td><td>█▅▃▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_accuracy</td><td>44.234</td></tr><tr><td>batch_loss</td><td>1.62486</td></tr><tr><td>epoch</td><td>4</td></tr><tr><td>train_accuracy</td><td>44.234</td></tr><tr><td>train_loss</td><td>1.52065</td></tr><tr><td>val_accuracy</td><td>47.07</td></tr><tr><td>val_loss</td><td>1.42666</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">decent-sweep-3</strong> at: <a href='https://wandb.ai/juno95/timm-cifar10-sweeps-5/runs/5600gpn4' target=\"_blank\">https://wandb.ai/juno95/timm-cifar10-sweeps-5/runs/5600gpn4</a><br> View project at: <a href='https://wandb.ai/juno95/timm-cifar10-sweeps-5' target=\"_blank\">https://wandb.ai/juno95/timm-cifar10-sweeps-5</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241217_103430-5600gpn4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: nyqeq6hd with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00017879501327875178\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_function: cross_entropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_name: mobilenetv3_small_100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jun/github/wandb_train_example/wandb/run-20241217_103607-nyqeq6hd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/juno95/timm-cifar10-sweeps-5/runs/nyqeq6hd' target=\"_blank\">devout-sweep-4</a></strong> to <a href='https://wandb.ai/juno95/timm-cifar10-sweeps-5' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/juno95/timm-cifar10-sweeps-5/sweeps/8428yi1m' target=\"_blank\">https://wandb.ai/juno95/timm-cifar10-sweeps-5/sweeps/8428yi1m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/juno95/timm-cifar10-sweeps-5' target=\"_blank\">https://wandb.ai/juno95/timm-cifar10-sweeps-5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/juno95/timm-cifar10-sweeps-5/sweeps/8428yi1m' target=\"_blank\">https://wandb.ai/juno95/timm-cifar10-sweeps-5/sweeps/8428yi1m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/juno95/timm-cifar10-sweeps-5/runs/nyqeq6hd' target=\"_blank\">https://wandb.ai/juno95/timm-cifar10-sweeps-5/runs/nyqeq6hd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Model saved with loss: 1.6866\n",
      "Epoch: 1/5\n",
      "Train Loss: 4.0242, Train Acc: 28.18%\n",
      "Val Loss: 1.6866, Val Acc: 39.56%\n",
      "--------------------------------------------------\n",
      "Model saved with loss: 1.4826\n",
      "Epoch: 2/5\n",
      "Train Loss: 1.6050, Train Acc: 42.07%\n",
      "Val Loss: 1.4826, Val Acc: 46.73%\n",
      "--------------------------------------------------\n",
      "Model saved with loss: 1.3095\n",
      "Epoch: 3/5\n",
      "Train Loss: 1.4250, Train Acc: 48.58%\n",
      "Val Loss: 1.3095, Val Acc: 53.02%\n",
      "--------------------------------------------------\n",
      "Model saved with loss: 1.1994\n",
      "Epoch: 4/5\n",
      "Train Loss: 1.3258, Train Acc: 52.21%\n",
      "Val Loss: 1.1994, Val Acc: 56.60%\n",
      "--------------------------------------------------\n",
      "Model saved with loss: 1.1215\n",
      "Epoch: 5/5\n",
      "Train Loss: 1.2217, Train Acc: 56.28%\n",
      "Val Loss: 1.1215, Val Acc: 61.02%\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_accuracy</td><td>▁▂▂▂▂▃▃▃▃▃▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████</td></tr><tr><td>batch_loss</td><td>█▂▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▁▁▂▂▂▁▂▁▂▂▁▁▂▁▁▂▂▁▁▂▂</td></tr><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_accuracy</td><td>▁▄▆▇█</td></tr><tr><td>train_loss</td><td>█▂▂▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▅▇█</td></tr><tr><td>val_loss</td><td>█▅▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_accuracy</td><td>56.278</td></tr><tr><td>batch_loss</td><td>1.1372</td></tr><tr><td>epoch</td><td>4</td></tr><tr><td>train_accuracy</td><td>56.278</td></tr><tr><td>train_loss</td><td>1.22168</td></tr><tr><td>val_accuracy</td><td>61.02</td></tr><tr><td>val_loss</td><td>1.12152</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">devout-sweep-4</strong> at: <a href='https://wandb.ai/juno95/timm-cifar10-sweeps-5/runs/nyqeq6hd' target=\"_blank\">https://wandb.ai/juno95/timm-cifar10-sweeps-5/runs/nyqeq6hd</a><br> View project at: <a href='https://wandb.ai/juno95/timm-cifar10-sweeps-5' target=\"_blank\">https://wandb.ai/juno95/timm-cifar10-sweeps-5</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241217_103607-nyqeq6hd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bvdstu0i with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 184\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00024948928609067273\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_function: cross_entropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_name: resnet18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jun/github/wandb_train_example/wandb/run-20241217_103737-bvdstu0i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/juno95/timm-cifar10-sweeps-5/runs/bvdstu0i' target=\"_blank\">gallant-sweep-5</a></strong> to <a href='https://wandb.ai/juno95/timm-cifar10-sweeps-5' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/juno95/timm-cifar10-sweeps-5/sweeps/8428yi1m' target=\"_blank\">https://wandb.ai/juno95/timm-cifar10-sweeps-5/sweeps/8428yi1m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/juno95/timm-cifar10-sweeps-5' target=\"_blank\">https://wandb.ai/juno95/timm-cifar10-sweeps-5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/juno95/timm-cifar10-sweeps-5/sweeps/8428yi1m' target=\"_blank\">https://wandb.ai/juno95/timm-cifar10-sweeps-5/sweeps/8428yi1m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/juno95/timm-cifar10-sweeps-5/runs/bvdstu0i' target=\"_blank\">https://wandb.ai/juno95/timm-cifar10-sweeps-5/runs/bvdstu0i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Model saved with loss: 1.2148\n",
      "Epoch: 1/5\n",
      "Train Loss: 1.7240, Train Acc: 40.36%\n",
      "Val Loss: 1.2148, Val Acc: 57.65%\n",
      "--------------------------------------------------\n",
      "Model saved with loss: 0.9461\n",
      "Epoch: 2/5\n",
      "Train Loss: 1.0850, Train Acc: 62.01%\n",
      "Val Loss: 0.9461, Val Acc: 66.85%\n",
      "--------------------------------------------------\n",
      "Model saved with loss: 0.8021\n",
      "Epoch: 3/5\n",
      "Train Loss: 0.8947, Train Acc: 68.73%\n",
      "Val Loss: 0.8021, Val Acc: 72.07%\n",
      "--------------------------------------------------\n",
      "Model saved with loss: 0.7198\n",
      "Epoch: 4/5\n",
      "Train Loss: 0.7883, Train Acc: 72.41%\n",
      "Val Loss: 0.7198, Val Acc: 75.16%\n",
      "--------------------------------------------------\n",
      "Model saved with loss: 0.6652\n",
      "Epoch: 5/5\n",
      "Train Loss: 0.7198, Train Acc: 74.73%\n",
      "Val Loss: 0.6652, Val Acc: 76.52%\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_accuracy</td><td>▁▁▂▂▂▄▄▄▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇███████████████</td></tr><tr><td>batch_loss</td><td>██▇▇▆▅▅▄▄▄▄▄▃▃▃▃▃▃▂▃▃▂▃▂▃▂▂▂▂▂▂▁▁▂▂▂▁▂▁▁</td></tr><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_accuracy</td><td>▁▅▇██</td></tr><tr><td>train_loss</td><td>█▄▂▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▆▇█</td></tr><tr><td>val_loss</td><td>█▅▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_accuracy</td><td>74.726</td></tr><tr><td>batch_loss</td><td>0.82659</td></tr><tr><td>epoch</td><td>4</td></tr><tr><td>train_accuracy</td><td>74.726</td></tr><tr><td>train_loss</td><td>0.71983</td></tr><tr><td>val_accuracy</td><td>76.52</td></tr><tr><td>val_loss</td><td>0.66521</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">gallant-sweep-5</strong> at: <a href='https://wandb.ai/juno95/timm-cifar10-sweeps-5/runs/bvdstu0i' target=\"_blank\">https://wandb.ai/juno95/timm-cifar10-sweeps-5/runs/bvdstu0i</a><br> View project at: <a href='https://wandb.ai/juno95/timm-cifar10-sweeps-5' target=\"_blank\">https://wandb.ai/juno95/timm-cifar10-sweeps-5</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241217_103737-bvdstu0i/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
